Write a review for the following abstract.

Abstract: Objective Most principal investigators support the concept 
of data sharing in principle, but few commit to sharing data in 
practice.1 One way shown to reduce this gap is if major 
stakeholders across the research life cycle implement policies 
to recommend or require data sharing. The objective of this 
study was to determine the prevalence and characteristics of 
data sharing policies.
Design This was a cross-sectional study of data sharing 
policies of health research funders, research ethics 
committees, clinical trial registries, peer-reviewed scientific 
journals, and research data repositories. It included the 55 
largest private and 55 largest public and philanthropic health 
research funders by annual health research expenditure, all 
national ethics committees, all clinical trial registries, the 5 
highest-impact peer-reviewed scientific journals by journal 
impact factor for each of the 59 fields of clinical medicine, and 
all research data repositories in clinical medicine. 
Investigators reviewed all official websites, online reports, 
and gray literature information sources of stakeholders for 
the presence of a data sharing policy. If present, investigators 
assessed its magnitude of support for data sharing. If it 
recommended or required data sharing, investigators 
assessed its characteristics. All data were abstracted in 
duplicate by 2 independent investigators who compared the 
relevant information against structured criteria on a 
prepiloted data extraction form and resolved disagreements 
by discussion and a third investigator.
Results Overall, 110 health research funders, 124 national 
ethics committees, 18 clinical trial registries, 273 peer-
reviewed scientific journals, and 410 research data 
repositories were included. More than half of health research 
funders either recommended (15 [15%]) or required (45 
[41%]) data sharing. These policies typically applied to all Table 16. Accurate Reporting of Funding in Articles on Research 
Funded by the ERC, MSCA, NIH, and NSF
Agency/year Articles, No. (%)Articles with 
accurately reported 
funding, No. (%)a
Total 209,635 (100.0) 120,051 (57.3)
Funding agency
  ERC 35,592 (17.0) 12,499 (35.1)
  MSCA 22,325 (10.7) 11,327 (50.7)
  NIH 85,933 (41.0) 45,153 (52.5)
  NSF 65,785 (31.4) 51,072 (77.6)
Publication year
  2014 10 (0.0) 0
  2015 595 (0.3) 36 (6.1)
  2016 3807 (1.8) 610 (16.0)
  2017 8735 (4.2) 2357 (27.0)
  2018 13,366 (6.4) 5672 (42.4)
  2019 16,880 (8.1) 7685 (45.5)
  2020 90,492 (43.2) 55,863 (61.7)
  2021 74,088 (35.3) 46,685 (63.0)
  2022 1662 (0.8) 1143 (68.8)
Abbreviations: ERC, European Research Council; MSCA, Marie Skłodowska-Curie Action; 
NIH, US National Institutes of Health; NSF , US National Science Foundation.
a Defined as including the funding agency and the correct grant number in the  
metadata tags.
www. peerreviewcongress.org     61data from only interventional studies, with justified 
exceptions, and specified data to be shared before a 
predetermined period with independent committee–
approved investigators for research proposal–approved 
purposes via third-party websites. Only 4 national ethics 
committees (3%) recommended data sharing. These policies 
typically applied to all studies, with justified exceptions, and 
specified data to be shared via third-party websites. Only 1 
clinical trial registry (6%) required data sharing. This policy 
applied to only interventional studies, with justified 
exceptions, and specified data to be shared via third-party 
websites. Almost two-thirds of peer-reviewed scientific 
journals either recommended (120 [44%]) or required (52 
[19%]) data sharing. These policies typically applied to only 
some data from all studies, with unjustified exceptions, and 
specified data to be shared with anyone for any purpose via 
third-party websites. Few research data repositories 
recommended (26 [6%]) or required (24 [6%]) data sharing. 
These policies typically applied to all data from all studies, 
with unjustified exceptions, and specified data to be shared 
with anyone for any purpose and via third-party websites.
Conclusions Data sharing imperatives were not met by 
most stakeholders.
Reference
1. Tan AC, Askie LM, Hunter KE, Barba A, Simes RJ, Seidler 
AL. Data sharing—trialists’ plans at registration, attitudes, 
barriers and facilitators: a cohort study and cross-sectional 
survey. Res Synth Methods . 2021;12(5):641-657. doi:10.1002/
jrsm.1500
1NHMRC Clinical Trials Centre, The University of Sydney, Sydney, 
Australia, aidan.tan@sydney.edu.au
Frequency of Data and Code Sharing in Medical 
Research: An Individual Participant Data Meta-
analysis of Metaresearch Studies  
Daniel G. Hamilton,1,2 Kyungwan Hong,3 Hannah Fraser,1 
Anisa Rowhani-Farid,3 Steve McDonald,4 Fiona Fidler,1,5 
Matthew J. Page4
Objective  Numerous metaresearch studies have investigated 
rates and predictors of data and code sharing in medicine. 
However, these studies have often been narrow in scope, 
focusing on some important aspects and predictors of sharing 
but not others. A systematic review and individual participant 
data (IPD) meta-analysis of this corpus of research is being 
conducted to provide an expansive picture of how availability 
rates have changed over time in medicine and what factors 
are associated with sharing.
Design  Ovid Embase, Ovid MEDLINE, MetaArXiv, medRxiv, 
and bioRxiv were searched up to July 1, 2021, for 
metaresearch studies that investigated data sharing, code 
sharing, or both among a sample of scientific articles 
presenting original research from the medical and health 
sciences (ie, primary articles). Two authors independently 
screened records and assessed risk of bias in the included 
studies. Key outcomes of interest included the prevalence of affirmative sharing declarations (declared availability) and 
availability as confirmed by the metaresearch authors (actual 
availability). The association between data and code 
availability and several factors (eg, year published, journal 
policy) were also examined. IPD were collected or requested 
from authors of eligible studies. A 2-stage approach to IPD 
meta-analysis was performed, with outcomes pooled using 
the Hartung-Knapp-Sidik-Jonkman method for random-
effects