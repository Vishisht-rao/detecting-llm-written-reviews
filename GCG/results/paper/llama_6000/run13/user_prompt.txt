Write a review for the following paper.

Abstract: The long term aim of the project carried out by the French National Space Agency (CNES) is to design a writing guide based on the real and regular writing of requirements. As a first step in the project, this paper proposes a linguistic analysis of requirements written in French by CNES engineers. The aim is to determine to what extent they conform to two rules laid down in INCOSE, a recent guide for writing requirements. Although CNES engineers are not obliged to follow any Controlled Natural Language in their writing of requirements, we believe that language regularities are likely to emerge from this task, mainly due to the writers’ experience. The issue is approached using natural language processing tools to identify sentences that do not comply with INCOSE rules. We further review these sentences to understand why the recommendations cannot (or should not) always be applied when specifying large-

1 Introduction: The study presented in this paper was conducted with a view to improving the writing of requirements at CNES (Centre National d’Études Spatiales).
The CNES and our laboratory have been collaborating for several years on questions concerning terminology, text management and the study of risks related to the use of language [1]. As linguists, we propose methods and results based on a corpus linguistics approach, assisted by tools such as parsers, statistical tools, terminology extractors, concordancers or scripting languages. More recently, we were approached on the specific problem of writing requirements.
The CNES is the French space agency and, as such, is responsible for designing space systems. Therefore, it has to draft specifications (that must clearly and precisely describe its needs) which are intended for companies that respond to the bids; and, in
not always clear, and that as a result there may be divergent interpretations, leading to additional costs, delays or even litigation (since requirements are part of the contract clauses).
In order to improve the quality of requirements, many projects have been developed by computational researchers to check the consistency of the requirements after they were written (see [2–4], among others). Still, we believe that the writing itself can be improved by proposing a guide closer to the actual way in which engineers write requirements.
In the present study, two kinds of documents were used: the Guide for Writing Requirements recommendations proposed by INCOSE (International Council on Systems Engineering) [5] (a controlled natural language, see below); and a subset of the specifications of a project: Pleiades (see below).
We propose a linguistic diagnosis of the way requirements are written in the project by comparing these requirements with the recommendations of the INCOSE guide.
The point of view underlying our approach is that guides for writing specifications are not fully adapted to the real writing process: they are sometimes too constraining, and sometimes insufficiently so. They are not written by linguists but by domain experts with a prescriptive point of view based on their experience. This is the case for example in the field of air-traffic control where the ICAO (International Civil Aviation Organization) phraseology is written by controllers [6]. Even if these guides are not always adapted to the reality of language use, we consider that they constitute a good starting point because of the experience of the domain experts. Our other starting point is constituted by specifications that are not written following the recommendations of a guide: this is the case at CNES.
Indeed, CNES engineers do not use a controlled natural language in order to write better specifications, only requirement management tools (such as IBM Rational DOORS). Nevertheless, they are all experienced in this type of writing. Thus, even if the writers do not consciously follow a controlled natural language, we assume the existence of regularities in the way they write requirements. Writers are indeed influenced both by existing specifications and by certain spontaneous regularities which tend to occur in each recurrent writing situation, two characteristics attributed to textual genres. According to Bhatia [7], a textual genre may be defined as “a recognizable communicative event characterized by a set of communicative purpose(s) identified and mutually understood by the members of the professional or academic community in which it regularly occurs”.
It can be noted that the notion of textual genre is not always properly distinguished from that of sublanguage. See for instance the definition given by Somers: “A sublanguage is an identifiable genre or text-type in a given subject field, with a relatively or even absolutely closed set of syntactic structures and vocabulary” [8]. Other authors such as Kurzon [9], Temnikova [10] or Kuhn [11] have highlighted this point. Historically, the most important difference is that the notion of sublanguage was proposed by Harris from a mathematical and distributional perspective [12], while that of
linguistic regularities are associated with speakers of the same community. This feature of spontaneous linguistic regularities has been characterized as normaison (“norming’) by the French Linguistic School of Rouen [15] as opposed to normalisation (“normalization”) that concerns the case where linguistic norms are imposed by an organism. In short, we could say that our aim is to propose a normalisation based on the identification of normaison, or, in other words, to improve the writing of specifications without imposing a standard that is too far removed from the engineers’ natural practice.
The paper comprises two main parts. In the first one (see section 2), we present the tool-assisted method used for making the diagnosis. In the second one (see section 3), we describe and discuss our preliminary results.

2 Methodology: Several guides for writing requirements exist, and most of them were designed to avoid undesirable properties of natural language (“unrestricted natural language brings with it a host of well-known problems” [16]), such as ambiguity, polysemy, vagueness, and so on [1, 17].
To ensure that these guidelines are close enough to actual practices, and thus really usable, we decided to carry out a diagnosis of the way the specifications are drafted at CNES and then to compare this process with the recommendations made by one of those guides. The aim is to evaluate the conformity of the requirements to the recommendations, and see if the latter can be brought closer to reality.
We will first briefly describe our corpus of requirements and the tools we used, and then the linguistic phenomena selected for study in the controlled natural language that we used as a reference.

2.1 Description of the corpus: A subset of the specifications of an Earth observation satellite called Pleiades, launched in 2011, was obtained from the CNES. From these specifications, we extracted the requirements, that is to say only those parts that play the role of contractual obligations between the CNES and its subcontractors. Requirements should not contain unnecessary information, such as examples or comments.
Requirements are intended to be autonomous; they are therefore supposed to have no link with the textual segments which precede or follow them. In the specifications we were given, the requirements were easily identifiable because they were framed by specific tags.
The requirements were all written in natural language, but some also contained tables or diagrams (which were removed, since they cannot be analyzed automatically). In theory, they should be fully understandable even without those figures – but in practice, this is not always the case.

2.2 Tools and resources: We used several tools to perform the tasks described in section 3. The syntactic analysis was done using Talismane [18], an open-source parser developed in our laboratory, while the open-source corpus processor Unitex [19] was used for sentence chunking. Short handmade Perl scripts were written for other needs (extraction of the requirements, detection of long sentences, and so on).
We also compared our corpus to two other corpora (reduced to the exact same size): (1) a handbook written by experts from the CNES about techniques and technologies used for building and operating spacecraft, intended for semi-experts, and (2) some articles from the French national newspaper Le Monde.

2.3 INCOSE recommendations: In order to compare the requirements corpus with a controlled natural language, we used the Guide for Writing Requirements recommendations proposed by INCOSE. The aim of this guide is presented as follows: “to draw together advice from a variety of existing standards into a single, comprehensive set of rules and objectives” (p. 10). It is quite general since it “is intended to cover the expression of requirements from across disciplines” (p. 12). INCOSE is therefore intended for engineers who write or review requirements. It can be clearly considered a “naturalist” controlled language (as opposed to the “formalist” approach) [20], whose goal is to facilitate