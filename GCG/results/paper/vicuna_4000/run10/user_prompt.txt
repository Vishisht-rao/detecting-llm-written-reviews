Write a review for the following paper.

Abstract: A recurrent neural network model of phonological pattern learning is proposed. The model is a relatively simple neural network with one recurrent layer, and displays biases in learning that mimic observed biases in human learning. Single-feature patterns are learned faster than two-feature patterns, and vowel or consonant-only patterns are learned faster than patterns involving vowels and consonants, mimicking the results of laboratory learning experiments. In non-recurrent models, capturing these biases requires the use of alpha features or some other representation of repeated features, but with a recurrent neural network, these elaborations are not necessary.

1 Introduction: Models of phonological pattern learning typically require large numbers of constraints or rules on where features can occur, and the presence of alpha features or some other representation of repeated features to allow certain patterns to be learned more quickly (Hayes and Wilson, 2008; Moreton et al., 2015). In human learning experiments, certain phonological patterns are learned more easily, particularly those involving multiple occurences of the same feature, such as a voicing agreement pattern.
In order to capture this bias towards singlefeature patterns, many models have some representation of repeated features. Alpha features are one example of this (see McCarthy (1988) for other approaches, such as feature geometry). Alpha features allow a model to learn a harmony pattern with only one predicate - that two features must be the same, having the value α. Without
alpha features, the model must learn two predicates - that the two features must either both have the value + or the value −. Therefore, there cannot be a bias towards single-feature patterns, because two-feature patterns also require learning two predicates (Moreton, 2012).
In addition to alpha features, many phonological learning models have to test or search over a large number of possible rules or constraints to learn a pattern. In models that use conjunctions of features as constraints (Hayes and Wilson, 2008; Moreton et al., 2015), if there areN features in the model, each with three possible values (+,−,±), there are 3N possible conjunctions of these features. With even a small number of features, the number of conjunctive constraints becomes very large.
Moreton, Pater, and Pertsova (2015) describe a cue-based learning model that uses these conjunctive constraints. Their model is a maximum entropy model trained by gradient descent on negative log-likelihood, and is related to the singlelayer perceptron. It successfully models the biases found in human phonological learning experiments, but still requires listing all possible constraint conjuncions in the input. In unpublished work, I have found that it is also possible to model these biases without constraint conjunctions using a feed-forward neural network with a hidden layer. See Alderete and Tupper (To appear) for an overview of other connectionist approaches to phonology.
Hare (1990) uses a recurrent neural network to model Hungarian vowel harmony without phonological rules or constraints. In Hare’s model, sequences of individual features describing vowels were the only inputs to the network. Some features in the input sequence could be left unspecified, and after training, fully specified feature sequences are output. While the model was only
trained on sequences of vowels, not entire words, Hare showed that recurrent neural networks were capable of modeling vowel harmony patterns using only individual features as input.
Rodd (1997) also uses recurrent neural networks to model Turkish vowel harmony. Individual phonemes rather than features were used as input to the networks, and the task was to predict the following phoneme. Rodd showed that the hidden units in small recurrent networks were able to represent distinctions between vowels and consonants, differences in sonority, and differences between front and back vowels. Although humans most likely do not perform the task of predicting the next phoneme in a word, Rodd showed that simple recurrent network could learn phonological regularities through differences in the distribution of phonemes.
Recurrent neural networks are capable of learning more than just vowel harmony patterns and feature representations, though. This paper describes a simple recurrent neural network model of phonological pattern learning that is biased towards learning single-feature patterns and patterns over only consonants or vowels without using alpha features, separate representations of consonants and vowels, or conjunctive constraints.

2 Model: The model used in these simulations is a simple recurrent neural network model. The ”words” that make up the patterns are the inputs in the first layer of the model. At each time step, the four features representing one phoneme are input to the network. The second layer is a hidden recurrent layer with ten neurons. The third layer is a log softmax layer with two output neurons. After the entire sequence is input to the model, the outputs at the final timestep will represent the log probabilities of the input belonging to each of the two classes, which will be referred to as IN the pattern or OUT of the pattern. The probability of a pattern being IN or OUT is the probability of it being allowed in the language.
The model was trained using gradient descent on negative log-likelihood with a learning rate of 0.01. Weights were adjusted after each word in the training data, rather than in batches. In each epoch of training, the order of presentation of the training data was randomly permuted. The output of the network was considered to be correct when the
log probability of the intended class was greater than the other class. This criterion for correctness was used because when the model is trained on a subset of the full pattern, it prevents overfitting to that subset. After each epoch of training, all training examples were checked for correctness. If the correct class was predicted for every training example, training was stopped.
The number of neurons in the recurrent layer is not important to the model. Ten neurons were chosen because with fewer neurons, the patterns tested could not be fully learned, and with more, the patterns were learned after only a few training epochs. More complex patterns or patterns requiring more features will likely require a larger number of neurons in this layer.

3 Patterns: The patterns used in testing the model used four phonological features - two consonant features, and two vowel features. Each feature has a value of +1 or -1. For consonants, the vowel features have a value of 0, and for vowels, the consonants have a value of 0. The consonant features used in these patterns are voicing (+/−voi) and place(+/−cor), and the vowel features are height (+/−hi) and backness (+/−back). This feature set corresponds to the consonants [d, t, k, g] and the vowels [i, u, æ, a]. All ”words” in the patterns have the form C1V1C2V2, where C and V range over the four consonants and vowels described by the four features, so there are 256 total. For each pattern, the words are divided into the two classes, IN and OUT, each with 128 examples.
Six patterns, dividing the 256 words based on their features, were created as simplified versions of real phonological patterns. The six feature combinations that are IN for each pattern are described in Table 1. The 128 words that do not fit these feature descriptions are in the OUT class of the pattern.
In pattern 1, there is a feature dependency between an adjacent consonant and vowel. In pattern 2, this dependency is between a non-adjacent consonant and vowel. Pattern 3 is a voice assimilation pattern where the two consonants must agree in voicing. In pattern 4, the consonants must disagree in voicing. In pattern 5, the two features relevant to the pattern are on the same consonant, and in pattern 6, they are on two separate consonants.
Moreton (2012) claims that there is an advan-
tage for learning intra-dimensional patterns over inter-dimensional patterns that requires alpha features to be captured by a model. The same advantage was also shown by Moreton, Pater, and Pertsova (2015) and Saffran and Thiessen (2003). In the six patterns described here, patterns 3 and 4 are intra-dimentional, single-feature patterns, and the rest are inter-dimensional, two-feature patterns. Therefore, patterns 3 and 4 should be learned faster than patterns 1, 2, and 6.
Pattern 5 is also an inter-dimensional pattern, but the two features are on the same segment rather than different segments like the rest of the patterns. In the experiments of Moreton