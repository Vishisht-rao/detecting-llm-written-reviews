Write a review for the following paper.

Abstract: This paper presents results on Speaker Recognition (SR) for children’s speech, using the OGI Kids corpus and GMM-UBM and GMM-SVM SR systems. Regions of the spectrum containing important speaker information for children are identified by conducting SR experiments over 21 frequency bands. As for adults, the spectrum can be split into four regions, with the first (containing primary vocal tract resonance information) and third (corresponding to highfrequency speech sounds) being most useful for SR. However, the frequencies at which these regions occur are from 11% to 38% higher for children. It is also noted that subband SR rates are lower for younger children. Finally results are presented of SR experiments to identify a child in a class (30 children, similar age) and school (288 children, varying ages). Class performance depends on age, with accuracy varying from 90% for young children to 99% for older children. The identification rate achieved for a child in a school is 81%.

1. Introduction: As human interaction with computers becomes more pervasive, and its applications become more private and sensitive, the value of automatic Speaker Recognition (SR) based on vocal characteristics increases.
The employment of SR technology for children could be beneficial in several application areas, including, child security and protection, and education. For instance, social networking sites are most popular with teenagers and young adults, with almost half of children aged from 8 to 17 who use the internet having set up their own profile on a social networking site [1]. An SR system that identifies a child based on his or her voice, and confirms the identity of the individual with whom the child is communicating, could be a valuable safeguard for a child engaged in social networking. Other possible applications are in education. For example, an interactive educational tutor that could identify each child in a class could automatically continue a previous lesson, adapt its content to suit the child, and log the child’s responses appropriately without the child needing to go through a formal login process.
Although automatic recognition of children’s speech has been the subject of considerable research effort, there is little published work on issues and algorithms related to automatic verification of a child’s identity from his or her speech. For example, we do not know how increases in inter- and intraspeaker variability for children’s speech [4] will affect SR performance. Variability is highest for young children, converging to adult values when children reach the age of 13. Even for young children there is some evidence that the degree of variability varies significantly between individuals [6].
characteristics of children’s speech are different from those of adult’s [3-5]. For example, children’s speech is characterized by higher pitch, and perceptually important features such as formants occur at higher frequencies [4]. Consequently, the impact of bandwidth reduction on speech recognition accuracy is greater for children’s speech than for adults [6, 7]. However, we do not know the significance of different frequency bands for SR for children, although the relevant studies for adult SR have been reported [2].
The success of Gaussian Mixture Model - Universal Background Model (GMM-UBM) and GMM-Support Vector Machine (GMM-SVM) approaches to adult SR motivated us to apply these techniques to our child SR task. The distribution of acoustic feature vectors for a population of speakers, is typically captured using a UBM (a speaker-independent GMM constructed using data from a variety of speakers and background conditions) [8, 9]. Speaker dependent GMMs are then built by MAP adaptation of the UBM [10]. Alternatively, discriminative approaches such as SVMs can be used, which have been shown to obtain comparable, and in some cases better, performance than GMM based systems. The combination of GMM supervectors, comprising the stacked parameters of the GMM components, with SVMs has also been successful [11]. SR systems usually employ score normalization to cope with score variability and to simplify decision threshold tuning.
This paper presents the results of experiments in SR for children’s speech and is organized as follows. Section 2 describes the OGI ‘Kid’s’ corpus of children’s speech, which is used in all experiments. Our SR systems are described in section 3, and our experiments and results are presented in section 4. Section 4.1 describes a study of the utility of the information in different frequency bands for children’s SR. Results of SR experiments for narrow band limited speech show that, as in the case of adults [2], the spectrum can be usefully partitioned into 4 regions, B1 to B4, with B1, B2, B3 and B4 corresponding to frequencies below 1.13kH, 0.63kHz to 3.8kHz, 2.1kHz to 5.53kHz and 3.4kHz to 8kHz, respectively. These frequencies are between 11% and 38% higher than those for adults [2]. Speaker information is concentrated in B1, which contains the primary vocal tract resonances, and B3, which contains high-frequency speech sounds such as fricatives. The speaker information in region B2 is masked by linguistic variation. It is also noted that narrow-band SR performance is consistently poorer for young children than for older children. Section 4.2 presents the results of verification and identification experiments for different age groups of children using full bandwidth speech. The best performance is obtained using a 64 component GMM-SVM system. Finally, with educational applications in mind, we simulate the problem of recognizing a single child in a class (30 children of a similar age) or a school (288 children varying in age from 5 to 13 years). Identification accuracy for a child in a class varies from 90% for the youngest children (5- 8years) to 99% for the oldest children (12 years old and
INTERSPEECH 2012 1836
above). The identification rate achieved for a child in a school is 81%.
2. The OGI kids’ speech corpus and data description
The OGI Kids’ Speech corpus [13] is a collection of spontaneous and read speech recorded at the Northwest Regional School District near Portland, Oregon. The CSLU Toolkit is used for data collection. It comprises recordings of words and sentences from approximately 1100 children. A gender-balanced group of approximately 100 children per grade from Kindergarten (5-6 year olds) through to grade 10 (15–16 year olds) participated in the collection. For each utterance, the text of the prompt was displayed on a screen, and a human recording of the prompt was played, in synchrony with facial animation using the animated 3D character “Baldi”. The subject then repeated the prompt, which was recorded via a head-mounted microphone and digitized at 16 bits and 16 kHz.
Four different test sets (10 seconds per utterance) from the
OGI data are used in the experiments presented in this paper.
TS1: To investigate the effect of different frequency bands on SR performance for general children’s speech, 359 speakers were chosen randomly (kindergarten to 10th grade).
TS2: To investigate the effect of different frequency bands on SR performance for speech from children of different ages, 3 different age groups were selected, each containing 288 speakers. These are AG1: kindergarten to 2nd grade (5-8 year olds), AG2: 3rd to 6th grade (8-12 year olds), and AG3: 7th to 10th grade (12-16 year olds).
TS3: To investigate the problem of identifying a single child in a school, two ‘schools’ of 288 randomly chosen speakers from kindergarten to 10th grade were chosen.
TS4: To investigate the problem of identifying a single child in a class, 12 ‘classes’ of children from 3 grade groups were chosen, each containing 30 children.

3. Speaker recognition systems: 

3.1. Signal Analysis: Feature extraction was performed as follows. Periods of silence were discarded using an energy-based Speech Activity Detector (SAD). The speech was then segmented into 20-ms frames (10-ms overlap) and a Hamming window was applied. The short-time magnitude spectrum, obtained by applying an FFT, is passed to a bank of 24 Mel-spaced triangular bandpass filters, spanning the frequency region from 0Hz to 8000Hz. Table 1 shows the center