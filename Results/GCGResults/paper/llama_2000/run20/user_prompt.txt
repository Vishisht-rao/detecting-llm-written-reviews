Write a review for the following paper.

Abstract: While the basic laws of Newtonian mechanics are well understood, explaining a physical scenario still requires manually modeling the problem with suitable equations and associated parameters. In order to adopt such models for artificial intelligence, researchers have handcrafted the relevant states, and then used neural networks to learn the state transitions using simulation runs as training data. Unfortunately, such approaches can be unsuitable for modeling complex real-world scenarios, where manually authoring relevant state spaces tend to be challenging. In this work, we investigate if neural networks can implicitly learn physical states of real-world mechanical processes only based on visual data, and thus enable longterm physical extrapolation. We develop a recurrent neural network architecture for this task and also characterize resultant uncertainties in the form of evolving variance estimates. We evaluate our setup to extrapolate motion of a rolling ball on bowl of varying shape and orientation using only images as input, and report competitive results with approaches that assume access to internal physics models and parameters.

1 Introduction: Animals can make remarkably accurate and fast predictions of physical phenomena in order to perform activities such as navigate, prey, or burrow. However, the nature of the mental models used to perform such predictions remains unclear and is still actively researched [9].
In contrast, science has developed an excellent formal understanding of physics; for example, mechanics is nearly perfectly described by Newtonian physics. While the constituent laws are simple and accurate, applying them to the description of a physical scenario is anything but trivial. First, the scenario needs to be abstracted (e.g., by segmenting the scene into rigid objects, estimating physical parameters such as mass, linear and angular velocity, etc., deciding which equations to apply, and so on). Then, prediction still requires the numerical integration of complex systems of equations. It is unlikely that this is the process of mental modeling followed by natural intelligences.
In an effort to develop model of physics that are more suitable for artificial intelligence, several authors have looked at the problem of learning physical predictors using deep neural networks. As a notable example, the recent Neural Physics Engine (NPE) [5] uses a neural network to learn the state transition function of mechanical systems. The state itself is handcrafted and includes physical parameters such as positions, velocities, and masses of rigid bodies. While this approach works well, a limitation is that it does not allow the network to learn its own abstraction of the physical system. This may prevent the model from learning efficient approximations of physics that are likely required to scale to complex real-world scenarios.
In this work, we ask whether a representation of the physical state of a mechanical system can be learned implicitly by a neural network, and whether this can be used to perform more accurate
ar X
iv :1
70 6.
02 17
9v 2
[ cs
.C V
] 8
J un
predictions. Compared to methods such as NPE, learning such a model is more challenging as no direct observations of the state of the system are available for training. Instead, the state is a hidden variable that must be inferred while solving a task for which supervision can be provided. As an example of such a task, we consider here the problem of long-term physical extrapolation.
Our approach to extrapolation is to develop a recurrent neural network architecture that not only contains an implicit representation of the state of the system, but is also able to evolve it through time. This differs from methods such as NPE that predict instantaneous variations of the system state, which are integrated in long-term predictions a-posteriori, after learning is complete. We show that accounting for the integration process during learning allows the network to learn an implicit representation of physics. Furthermore, we show that, in relatively complex physical setups, the resulting predictions can be competitive to a modified version of NPE, even when the inputs to the extrapolator are visual observations of the physical system instead of a direct knowledge of its initial state.
Since physical extrapolation is inherently ambiguous, we allow the model to explicitly estimate its prediction uncertainty by estimating the variance of a Gaussian observation model. We show that this modification further improves the quality of long-term predictions.
Empirically, we push our model by considering scenarios beyond the “flat” ones considered in most recent papers, such as objects sliding on planes and colliding, and look for the first time at the case of an object rolling on a non-trivial 3D shape, namely a bowl of varying shape and orientation, where both linear and angular momenta are tightly coupled.
As a final benefit of learning with long-term physical predictions, we show that our model is able, with minimal modifications, to learn not only to extrapolate physical trajectories, but also to interpolate them. Remarkably, interpolation is still obtained by computing the trajectory in a feed-forward manner, from the first to the last time step.
The rest of the paper is organized as follows. The relation of our work to the literature is discussed in section 2. The detailed structure of the proposed neural networks is given and motivated in section 3. These networks are extensively evaluated on a large dataset of simulated physical experiments in section 5. A summary of our finding can be found in section 6.

2 Related work: In this work we address the problem of long-term prediction from observation in a physical environment without voluntary perturbation, which is done by an implicit learning of physical laws. Our work is closely related to a range of recent works in the machine learning community.
Learning intuitive physics. To the best of our knowledge [4] was the first approach to tackle intuitive physics with the aim to answer a set of intuitive questions (e.g., will it fall?) using physical simulations. Their simulations, however, used a sophisticated physics engine that incorporates prior knowledge about Newtonian physical equations. More recently [17] also used static images and a graphics rendering engine (Blender) to predict movements and directions of forces from a single RGB image. Motivated by the recent success of deep learning for image processing (e.g., [12, 10]), they used a convolutional architecture to understand dynamics and forces acting behind the scenes from a static image and produced a “most likely motion" rendered from a graphics engine. In a different framework, [14] and [15] also used the power of deep learning to extract an abstract representation of the concept of stability of block towers purely from images. These approaches successfully demonstrated that not only was a network able to accurately predict the stability of the block tower but in addition, it could identify the source of the instability. Other approaches such as [2] or [7] also attempted to learn intuitive physics of objects through manipulation. These approaches, however, do not attempt to precisely model the evolution of the physical world.
Learning dynamics. Learning the evolution of an object’s position also implies to learn about the object’s dynamics regardless of any physical equations. While most successful techniques used LSTM-s [11], recent approaches show that propagation can also be done using a single crossconvolution kernel. The idea was further developed in [27] in order to generate a next possible image frame from a single static input image. The concept has been shown to have promising performance regarding longer term predictions on the moving MNIST dataset in [6]. The work of [19] also shows that an internal hidden state can be propagated through time using a simple deep recurrent architecture.
These results motivated us to propagate tensor based state representations instead of a single vector representation using a series of convolutions. Adversarial losses have also been used in [18] which shows good results in video segmentation. In the future we also aim to experiment with approaches inspired by [27].
Learning physics. The works of [26] and its extension [25] propose methods to learn physical properties of scenes and objects. However, in [26] the MCMC sampling based approach assumes the complete knowledge of the physical equations to estimate the correct physical parameters. In [25] deep learning has been used more extensively to replace the MCMC based sampling but this work also employs an explicit encoding and computation of physical laws to regress the output of their tracker. [22] also used physical laws to predict the movement of a pillow from unlabelled data though their approach was only applied to a fixed number of frames.
In another related approach [8] attempted to build an internal representation of the physical world. Using a billiard board with an external simulator they built a network which observing four frames and an applied force, was able to predict the 20 next object velocities. Generalization in this work was made using an LSTM in the intermediate representations. The process can be interpreted as iterative since frame generation is made to provide new inputs to the network. This can also be seen as a regularization process to avoid the internal representation of dynamics to decay over time which is different to our approach in which we try to build a stronger internal representation that will attempt to avoid such decay.
Other research attempted to abstract the physics engine enforcing the laws of physics