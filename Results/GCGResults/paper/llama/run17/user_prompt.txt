Write a review for the following paper.

Abstract: Semisupervised learning has emerged as a popular framework for improving modeling accuracy while controlling labeling cost. Based on an extension of stochastic composite likelihood we quantify the asymptotic accuracy of generative semi-supervised learning. In doing so, we complement distribution-free analysis by providing an alternative framework to measure the value associated with different labeling policies and resolve the fundamental question of how much data to label and in what manner. We demonstrate our approach with both simulation studies and real world experiments using naive Bayes for text classification and MRFs and CRFs for structured prediction in NLP.

1 Introduction: Semisupervised learning (SSL) is a technique for estimating statistical models using both labeled and unlabeled data. It is particularly useful when the costs of obtaining labeled and unlabeled samples are different. In particular, assuming that unlabeled data is more easily available, SSL provides improved modeling accuracy by adding a large number of unlabeled samples to a relatively small labeled dataset.
The practical value of SSL has motivated several attempts to mathematically quantify its value beyond traditional supervised techniques. Of particular importance is the dependency of that improvement on the amount of unlabeled and labeled data. In the case of structured prediction the accuracy of the SSL estimator depends also on the specific manner in which sequences are labeled. Focusing on the framework of generative or likelihood-based SSL applied to classification and structured prediction we identify the following questions which we address in this paper. Q1: Consistency (classification). What combinations of labeled and unlabeled data lead to precise models in the limit of large data. Q2: Accuracy (classification). How can we quantitatively express the estimation accuracy for a particular generative model as a function of the amount of labeled and unlabeled data. What is the improvement in estimation accuracy resulting from replacing an unlabeled example with a labeled one. Q3: Consistency (structured prediction). What strategies for sequence labeling lead to precise models in the limit of large data. Q4: Accuracy (structured prediction). How can we quantitatively express the estimation quality for a particular model and structured labeling strategy. What is the improvement in estimation accuracy resulting from replacing one labeling strategy with another. Q5: Tradeoff (classification and structured prediction). How can we quantitatively express the tradeoff between the two competing goals of improved prediction accuracy and low labeling cost. What are the possible ways to resolve that tradeoff optimally within a problem-specific context.
∗To whom correspondence should be addressed. Email: jvdillon@gatech.edu
Q6: Practical Algorithms. How can we determine how much data to label in practical settings. The first five questions are of fundamental importance to SSL theory. Recent related work has concentrated on large deviation bounds for discriminative SSL as a response to Q1 and Q2 above. While enjoying broad applicability, such non-parametric bounds are weakened when the model family’s worst-case is atypical. By forgoing finite sample analysis, our approach complements these efforts and provides insights which apply to the specific generative models under consideration. In presenting answers to the last question, we reveal the relative merits of asymptotic analysis and how its employ, perhaps surprisingly, renders practical heuristics for controlling labeling cost.
Our asymptotic derivations are possible by extending the recently proposed stochastic composite likelihood formalism [5] and showing that generative SSL is a special case of that extension. The implications of this analysis are demonstrated using a simulation study as well as text classification and NLP structured prediction experiments. The developed framework, however, is general enough to apply to any generative SSL problem. As in [7], the delta method transforms our results from parameter asymptotics to prediction risk asymptotics. We omit these results for lack of space.

2 Related Work: Semisupervised learning has received much attention in the past decade. Perhaps the first study in this area was done by Castelli and Cover [3] who examined the convergence of the classification error rate as a labeled example is added to an unlabeled dataset drawn from a Gaussian mixture model. Nigam et al. [9] proposed a practical SSL framework based on maximizing the likelihood of the observed data. An edited volume describing more recent developments is [4].
The goal of theoretically quantifying the effect of SSL has recently gained increased attention. Sinha and Belkin [11] examined the effect of using unlabeled samples with imperfect models for mixture models. Balcan and Blum [1] and Singh et al. [10] analyze discriminative SSL using PAC theory and large deviation bounds. Additional analysis has been conducted under specific distributional assumptions such as the “cluster assumption”, “smoothness assumption” and the “low density assumption.”[4] However, many of these assumptions are criticized in [2].
Our work complements the above studies in that we focus on generative as opposed to discriminative SSL. In contrast to most other studies, we derive model specific asymptotics as opposed to non-parametric large deviation bounds. While such bounds are helpful as they apply to a broad set of cases, they also provide less information than model-based analysis due to their generality. Our analysis, on the other hand, requires knowledge of the specific model family and an estimate of the model parameter. The resulting asymptotics, however, apply specifically to the case at hand without the need of potentially loose bounds.
We believe that our work is the first to consider and answer questions Q1-Q6 in the context of generative SSL. In particular, our work provides a new framework for examining the accuracy-cost SSL tradeoff in a way that is quantitative, practical, and model-specific.

3 Stochastic SSL Estimators: Generative SSL [9, 4] estimates a parametric model by maximizing the observed likelihood incorporating L labeled and U unlabeled examples
ℓ(θ) =
L ∑
i=1
log pθ(X (i), Y (i)) +
L+U ∑
i=L+1
log pθ(X (i)) (1)
where pθ(X (i)) above is obtained by marginalizing the latent label
∑
y pθ(X (i), y). A classical example is
the naive Bayes model in [9] where pθ(X,Y ) = pθ(X |Y )p(Y ), pθ(X |Y = y) = Mult([θy]1, . . . , [θy]V ). The framework, however, is general enough to apply to any generative model pθ(X,Y ).
To analyze the asymptotic behavior of the maximizer of (1) we assume that the ratio between labeled to unlabeled examples λ = L/(L + U) is kept constant while n = L + U → ∞. More generally, we assume a stochastic version of (1) where each one of the n samples X(1), . . . , X(n) is labeled with probability λ
ℓn(θ) = n ∑
i=1
Z(i) log pθ(X (i), Y (i)) +
n ∑
i=1
(1− Z(i)) log pθ(X(i)), Z(i) ∼ Bin(1, λ). (2)
The variable Z(i) above is an indicator taking the value 1 with probability λ and 0 otherwise. Due to the law of large numbers for large n we will have approximately L = nλ labeled samples and U = n(1−λ) unlabeled samples thus achieving the asymptotic behavior of (1).
Equation (2) is sufficient to handle the case of classification. However, in the case of structured prediction we may have sequencesX(i), Y (i) where for each i some components of the label sequence Y (i) are missing and some are observed. For example one label sequence may be completely observed, another may be completely unobserved, and a third may have the first half labeled and the second half not.
More formally, we assume the existence of a sequence labeling policy or strategy ℘ which maps label
sequences Y (i) = (Y (i) 1 , . . . , Y (i) m ) to a subset corresponding to the observed labels ℘(Y (i)) ⊂ {Y (i)1 , . . . , Y (i) m }. To achieve full generality we allow the labeling policy ℘ to be stochastic, leading to different subsets of {Y (i)1 , . . . , Y (i) m } with different probabilities. A simple “all or nothing” labeling policy could label the entire sequence with probability λ and otherwise ignore it. Another policy may label the entire sequence, the first half, or ignore it completely with equal probabilities
℘(Y )=
